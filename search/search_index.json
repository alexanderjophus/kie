{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to KIE (Knowledge Is Everything)!","text":"<p>A collection of microservices to predict who will be good at hockey.</p>"},{"location":"#background","title":"Background","text":"<p>Looking for talk ideas for gophercon, I asked chatGPT what talk ideas might be good. It listed 10. I chose recommendation services, as it's a thing I've tried in the past, but never successfully implemented. After some refining, I decided to make a recommendation service for hockey players. ChatGPT helped breakdown the problem into 4 major steps, check outline for more info.</p>"},{"location":"#tools","title":"Tools","text":"<ul> <li>Go, absolutely everywhere - because why not?</li> <li>Pachyderm - because it's awesome</li> <li>gRPC/buf</li> </ul>"},{"location":"#deploying","title":"Deploying","text":""},{"location":"#local","title":"Local","text":"<pre><code># Start pachyderm\nhelm install pachd pachyderm/pachyderm -n pachd --create-namespace \\\n--set deployTarget=LOCAL \\\n--set proxy.enabled=false\n\n# Run the pachyderm operator (github.com/alexanderjophus/pachyderm-operator)\n\n# Apply kustomize files\nkubectl apply -k deploy/base\n</code></pre>"},{"location":"#prod","title":"Prod","text":"<p>lol</p>"},{"location":"pipeline-outline/","title":"Pipeline Outline","text":"<p>The technical architecture of the project.</p> <pre><code>graph LR\n\n    A[Ingestion] --&gt; B[Data Cleaner]\n    B --&gt; C[Feature Extraction]\n    C --&gt; D[Model Training]\n    D --&gt; E[API serving model]</code></pre>"},{"location":"pipeline-outline/#data-ingestion","title":"Data Ingestion","text":"<p>We expose a gRPC/REST API to allow us to control what data we're processing. The main idea here is to expose a very lightweight service that allows us to hit the NHL API, collect data, and upload that data to pachyderm.</p> <p>We then pass that data into a cleaning/transformation pipeline that takes the raw data and cleans it up, and transforms it into a format that is more useful for our model.</p>"},{"location":"pipeline-outline/#feature-extraction","title":"Feature Extraction","text":"<p>Secondly we have the extraction pipeline. This pipeline takes stats and transforms them into something usable for the training pipeline. A lot of data like goals/assists translate very nicely into training models, however some data like where the game is/time of day, etc is a bit more difficult to use. We'll need to do some feature engineering to make this data usable.</p> <p>Note: We may in the future be able to feed data back into the model. For example, it's more impressive if a player scores against a hot goalie/shutdown defencemen rather than a cold goalie/rookie defencemen. We can use this data to help train our model.</p>"},{"location":"pipeline-outline/#model-training","title":"Model Training","text":"<p>Thirdly we do the exciting thing. Training a model. We'll use the data we've collected and the features we've extracted to train a model. We'll use this model to predict how good a player will be.</p>"},{"location":"pipeline-outline/#model-serving","title":"Model Serving","text":"<p>Lastly we'll serve our model. We'll expose a gRPC/REST API that allows us to query our model and get predictions.</p>"},{"location":"state-of-things/","title":"State of Things","text":"<p>Using the model described at the bottom of the page to describe how 'done' a component is.</p>"},{"location":"state-of-things/#components","title":"Components","text":""},{"location":"state-of-things/#ui-input","title":"UI Input","text":"<p>5 - I'd like a CLI tool for this at first. Potentially uploading data player by player, as well as a 'star' flag for each player.</p>"},{"location":"state-of-things/#ingestion","title":"Ingestion","text":"<p>50 - We have a gRPC server that can receive data, it then puts that data into a pachyderm repo</p>"},{"location":"state-of-things/#cleaning","title":"Cleaning","text":"<p>50 - We have a service that converts a json response into a tidy csv with relevant data only. It needs tests, and some tweaks to the data it's outputting.</p>"},{"location":"state-of-things/#features","title":"Features","text":"<p>10 - We have a service that can take a csv and output a csv with features. It's very hacked together, need to read up on features again too.</p>"},{"location":"state-of-things/#training","title":"Training","text":"<p>5 - I'd like a job that can be triggered on demand that will train a model. This way we're not training on every commit. I'd like to start with a simple linear regression model. It also needs to store the model somewhere.</p>"},{"location":"state-of-things/#predictor","title":"Predictor","text":"<p>5 - After the model has been trained, this service needs to be redeployed to pick up the model. Given a players ID, it should look up that players data so far and predict their future.</p>"},{"location":"state-of-things/#51050mvp-model","title":"5/10/50/MVP Model","text":""},{"location":"state-of-things/#5","title":"5","text":"<p>The component has been envisioned.</p> <ul> <li>The goal is somewhat documented.</li> </ul>"},{"location":"state-of-things/#10","title":"10","text":"<p>The component has been designed.</p> <ul> <li>The goal is documented.</li> <li>The core component has been developed.</li> <li>The component has not necessarily been tested, neither manually, or through automated tests.</li> </ul>"},{"location":"state-of-things/#50","title":"50","text":"<p>The component is structured.</p> <ul> <li>The goal is documented.</li> <li>The core component has been developed.</li> <li>The component has been tested, either manually, or through automated tests.</li> <li>The component has been documented.</li> </ul>"},{"location":"state-of-things/#mvp","title":"MVP","text":"<p>The component is 'ready' by all accounts.</p> <ul> <li>The component has been developed.</li> <li>The component has been tested through automated tests.</li> <li>The component has been documented thoroughly.</li> </ul>"},{"location":"user-guide/","title":"User Guide","text":"<p>The user journeys a person might take.</p>"},{"location":"user-guide/#todo-updating-the-model","title":"TODO: Updating the Model","text":"<pre><code>graph LR\n\n    A[User] --&gt; B(???)\n    B --&gt; C[Ingestion]</code></pre> <p>Eventually, we'll have a UI that allows you to upload data as you see fit, currently this is done through the gRPC API on a player by player basis.</p> <p>I'm more inclined to make a CLI tool that allows you to upload data, as it's easier for me to make.</p>"},{"location":"user-guide/#todo-querying-the-model","title":"TODO: Querying the Model","text":"<pre><code>graph LR\n\n    A[User] --&gt; B[API]</code></pre> <p>We expose a gRPC/REST API to allow us to query the model and get predictions.</p>"},{"location":"howto/use/","title":"How to Use","text":"<p>Still figuring this out. The goal is to load in a bunch of players on startup, and then have a gRPC/REST API that allows you to query the model and get predictions.</p>"}]}